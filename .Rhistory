geom_point(data = train_predictions, aes(x = police, y = violent), color = "darkgreen", alpha = 0.5) +
geom_line(data = train_predictions, aes(x = police, y = .pred), color = "darkgreen", size = 1, alpha = 0.3) +
geom_segment(data = train_predictions, aes(x = police, y = .pred, yend = violent), color = "green", size = 1, alpha = 0.3) +
geom_smooth(data = predictions, aes(x = police, y = violent), color = "blue", size = 1, alpha = 0.3, method = "lm") +
geom_point(data = predictions, aes(x = police, y = violent), color = "blue", alpha = 0.5) +
labs(title = "Actual vs Predicted Violent Crime Rate",
x = "Police Presence",
y = "Violent Crime Rate")
View(predictions)
# Load necessary libraries
library(tidymodels)
library(caret)
library(ggplot2)
# Set seed for reproducibility
set.seed(123)
# Step 1: Split the Data into Training and Testing Sets
data_split <- initial_split(af_crime93, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)
# Step 2: Ensure test_data has the same factor levels as train_data
train_data$state <- as.factor(train_data$state)
test_data$state <- factor(test_data$state, levels = levels(train_data$state))
# Step 3: Check for Multicollinearity (Fixing Rank Deficiency)
cor_matrix <- cor(train_data %>% select(-violent, -state))  # Exclude target variable
high_corr <- findCorrelation(cor_matrix, cutoff = 0.9)  # Identify highly correlated predictors
train_data <- train_data %>% select(-all_of(high_corr))  # Drop correlated variables
test_data <- test_data %>% select(-all_of(high_corr))  # Keep test data consistent
# Step 4: Normalize the Data (Excluding Categorical Variables)
preProc <- preProcess(train_data %>% select(-state), method = c("center", "scale"))
# Apply Normalization to Training and Testing Datasets (excluding categorical variables)
train_data_norm <- predict(preProc, train_data %>% select(-state))
test_data_norm <- predict(preProc, test_data %>% select(-state))
# Add back the state column
train_data_norm$state <- train_data$state
test_data_norm$state <- test_data$state
# Step 5: Define and Train the Linear Regression Model
lm_spec <- linear_reg() %>%
set_engine("lm")
# Fit the Model Using Training Data
lm_fit <- lm_spec %>%
fit(violent ~ ., data = train_data_norm)
# Step 6: Make Predictions on Test Data
predictions <- predict(lm_fit, new_data = test_data_norm) %>%
bind_cols(test_data_norm)
# Step 7: Make Predictions on Training Data
train_predictions <- predict(lm_fit, new_data = train_data_norm) %>%
bind_cols(train_data_norm)
# Step 8: Visualizing Actual vs Predicted Values
ggplot() +
geom_point(data = train_predictions, aes(x = police, y = violent), color = "darkgreen", alpha = 0.5) +
geom_line(data = train_predictions, aes(x = police, y = .pred), color = "darkgreen", linewidth = 1, alpha = 0.3) +
geom_segment(data = train_predictions, aes(x = police, y = .pred, yend = violent), color = "green", linewidth = 1, alpha = 0.3) +
geom_smooth(data = predictions, aes(x = police, y = violent), color = "blue", linewidth = 1, alpha = 0.3, method = "lm") +
geom_point(data = predictions, aes(x = police, y = violent), color = "blue", alpha = 0.5) +
labs(title = "Actual vs Predicted Violent Crime Rate",
x = "Police Presence",
y = "Violent Crime Rate")
crime_data93 = af_crime93
dim(crime_data93)
# There are 51 observations and 8 variables
# One of which is the target variable = violent
library(tidymodels)
set.seed(123)
# Define Ridge Regression Model
ridge_spec <- linear_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet")
# Create Cross-validation Folds
cv_folds <- vfold_cv(train_data, v = 5)
set.seed(123)
# Split the data into 80% training and 20% testing
data_split = initial_split(af_crime93, prop = 0.8)
train_data = training(data_split)
test_data = testing(data_split)
library(tidymodels)
set.seed(123)
# Define Ridge Regression Model
ridge_spec <- linear_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet")
# Create Cross-validation Folds
cv_folds <- vfold_cv(train_data, v = 5)
# Set up Grid of Lambda Values to Try
lambda_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 100)
# Define Recipe
ridge_recipe <- recipe(violent ~ ., data = train_data)
# Create Workflow
ridge_wf <- workflow() %>%
add_model(ridge_spec) %>%
add_recipe(ridge_recipe)
# Tune the Model
tune_results <- tune_grid(
ridge_wf,
resamples = cv_folds,
grid = lambda_grid
)
# Find Best Lambda
best_lambda <- select_best(tune_results, metric = "rmse")
library(tidymodels)
set.seed(123)
# Define Ridge Regression Model
ridge_spec <- linear_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet")
# Create Cross-validation Folds
cv_folds <- vfold_cv(train_data, v = 5)
ridge_recipe <- recipe(sale.price ~ gross.square.feet + state, data = train) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%  # Convert categorical variables to numeric
step_normalize(all_numeric_predictors())  # Normalize numeric predictors
# Set up Grid of Lambda Values to Try
lambda_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 100)
# Define Recipe
ridge_recipe <- recipe(violent ~ ., data = train_data)
# Create Workflow
ridge_wf <- workflow() %>%
add_model(ridge_spec) %>%
add_recipe(ridge_recipe)
# Tune the Model
tune_results <- tune_grid(
ridge_wf,
resamples = cv_folds,
grid = lambda_grid
)
# Find Best Lambda
best_lambda <- select_best(tune_results, metric = "rmse")
library(tidymodels)
set.seed(123)
# Define Ridge Regression Model
ridge_spec <- linear_reg(penalty = tune(), mixture = 0) %>%
set_engine("glmnet")
# Create Cross-validation Folds
cv_folds <- vfold_cv(train_data, v = 5)
# Define Recipe (Ensure Correct Response Variable)
ridge_recipe <- recipe(sale.price ~ gross.square.feet + state, data = train_data) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%  # Convert categorical variables to numeric
step_normalize(all_numeric_predictors())  # Normalize numeric predictors
crime_data93 = af_crime93
summary(crime_93)
summary(crime_data93)
str(crime_data93)
set.seed(123)
# Split the data into 80% training and 20% testing
data_split = initial_split(af_crime93, prop = 0.8)
train_data = training(data_split)
test_data = testing(data_split)
# Normalize the data (excluding the first column, which is likely categorical)
preProc <- preProcess(train_data[, -1], method = c("center", "scale"))
# Apply normalization to training and testing datasets
train_data_norm <- predict(preProc, train_data[, -1])
test_data_norm <- predict(preProc, test_data[, -1])
set.seed(123)
lm_spec <- linear_reg() %>%
set_engine("lm")
crime_data93 = af_crime93
set.seed(123)
# Split the data into 80% training and 20% testing
data_split = initial_split(af_crime93, prop = 0.8)
train_data = training(data_split)
test_data = testing(data_split)
View(test_data)
View(train_data)
crime_model <- lm(violent ~ poverty + single + metro + white + highschool, data = train_data)
summary(crime_model)
library(car)
vif(crime_model)
install.packages("car")
library(car)
vif(crime_model)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
vif(crime_model)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
predictions <- predict(crime_model, test_data)
actual_values <- test_data$violent
rmse <- sqrt(mean((predictions - actual_values)^2))
print(rmse)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
lm_spec <- linear_reg() %>%
set_engine("lm")
lm_fit <- lm_spec %>%
fit(violent ~ poverty + single + metro + white + highschool, data = train_data)
lm_fit
print(lm_fit)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
test_predictions <- predict(lm_fit, new_data = test_data) %>%
bind_cols(test_data)
metrics <- yardstick::metrics(test_predictions, truth = violent, estimate = .pred)
print(metrics)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
ggplot(test_predictions, aes(x = .pred, y = violent - .pred)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(title = "Residual Plot", x = "Predicted Values", y = "Residuals")
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
crime_data93 = af_crime93
View(crime_data93)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
set.seed(123)
# Split the data into 80% training and 20% testing
data_split = initial_split(af_crime93, prop = 0.8)
train_data = training(data_split)
test_data = testing(data_split)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
# Define logistic regression model
log_spec <- logistic_reg() %>%
set_engine("glm")
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
# Create workflow
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder, poverty, single, metro, white, highschool)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
# Create workflow
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder, poverty, single, metro, white, highschool)
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder, poverty, single, metro, white, highschool)
library(tidymodels)
# Set CRAN mirror first
options(repos = c(CRAN = "https://cloud.r-project.org"))
# Load necessary libraries
library(tidyverse)
if (!requireNamespace("stevedata", quietly = TRUE)) {
install.packages("stevedata")
}
library(stevedata)
if (!requireNamespace("tidytuesdayR", quietly = TRUE)) {
install.packages("tidytuesdayR")
}
library(tidytuesdayR)
if (!requireNamespace("caret", quietly = TRUE)) {
install.packages("caret")
}
library(caret)
library(tidymodels)
library(glmnet)
install.packages("car")
library(car)
# Create workflow
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder, poverty, single, metro, white, highschool)
Create workflow
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder, poverty, single, metro, white, highschool)
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder, poverty, single, metro, white, highschool)
no
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder + poverty + single + metro + white + highschool)
View(log_wf)
# Fit model
fit <- fit(log_wf, data = train_data)
library(tidymodels)
# Ensure outcome variable is a factor
health <- health %>%
mutate(violent = as.factor(violent))  # Convert numeric outcome to categorical
# Ensure outcome variable is a factor
health <- crime_data93 %>%
mutate(violent = as.factor(violent))  # Convert numeric outcome to categorical
# Split data
set.seed(123)
data_split <- initial_split(health, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)
# Define logistic regression model
log_spec <- logistic_reg() %>%
set_engine("glm")
# Create workflow
log_wf <- workflow() %>%
add_model(log_spec) %>%
add_formula(violent ~ murder + poverty + single + metro + white + highschool)
# Fit model
fit <- fit(log_wf, data = train_data)
View(health)
crime_data93 = af_crime93
set.seed(123)
# Split the data into 80% training and 20% testing
data_split = initial_split(af_crime93, prop = 0.8)
train = training(split)
set.seed(123)
# Split the data into 80% training and 20% testing
data_split <- initial_split(crime_data93, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)
# Define logistic regression model
lm_spec <- linear_reg() %>%
set_engine("lm")
# Create workflow
lm_wf <- workflow() %>%
add_model(lm_spec) %>%
add_formula(violent ~ murder + poverty + single + metro + white + highschool)
# Fit model
fit <- fit(lm_wf, data = train_data)
# Evaluate model
preds <- predict(fit, test_data) %>%
bind_cols(test_data)
View(preds)
rmse_value <- rmse(preds, truth = violent, estimate = .pred)
View(rmse_value)
print(paste("RMSE:", round(rmse_value$.estimate, 4)))
